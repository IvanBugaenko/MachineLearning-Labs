{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Самостоятельно реализовать BoW, TF-IDF\n",
    "2. Решить задачу классификации с понижением размерности. Использовать самостоятельно реализованные модели из предыдущих ЛР.\n",
    "3. Решить задачу мягкой кластеризации (ТМ) с помощью LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(Path(os.getcwd()).parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy as sp\n",
    "\n",
    "\n",
    "nlp = sp.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def tokenization(text):\n",
    "    return \" \".join([token.lemma_ for token in nlp(text) if (token.lower_ not in nlp.Defaults.stop_words) and (not token.is_punct)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Собственная реализация BagOfWords и TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mylib.NLP.CountVectorizer import CountVectorizer\n",
    "import sklearn.feature_extraction.text as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1.\n",
      "  0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 1. 2.]\n",
      " [0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 2. 1. 0. 1. 1. 4. 0. 1. 0. 0. 4. 1. 0. 1.\n",
      "  0. 2. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0.\n",
      "  1. 0. 0. 1. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Пожалуй': 1,\n",
       " 'а': 1,\n",
       " 'аудитория': 1,\n",
       " 'будет': 1,\n",
       " 'будни': 1,\n",
       " 'будут': 1,\n",
       " 'бы': 2,\n",
       " 'в': 1,\n",
       " 'великолепный': 1,\n",
       " 'вернут': 1,\n",
       " 'все': 2,\n",
       " 'всё': 1,\n",
       " 'ему': 1,\n",
       " 'если': 2,\n",
       " 'зрительская': 1,\n",
       " 'и': 5,\n",
       " 'который': 1,\n",
       " 'круги': 1,\n",
       " 'легкой': 1,\n",
       " 'любых': 1,\n",
       " 'меньше': 4,\n",
       " 'на': 1,\n",
       " 'написал': 1,\n",
       " 'не': 1,\n",
       " 'нервы': 1,\n",
       " 'ниже': 2,\n",
       " 'общем': 1,\n",
       " 'пару': 1,\n",
       " 'первые': 1,\n",
       " 'положительную': 1,\n",
       " 'поможет': 1,\n",
       " 'посмотрел': 1,\n",
       " 'при': 1,\n",
       " 'просто': 1,\n",
       " 'рейтинги': 1,\n",
       " 'рецензию': 1,\n",
       " 'руки': 1,\n",
       " 'с': 1,\n",
       " 'своя': 1,\n",
       " 'сезонов': 2,\n",
       " 'сериал': 1,\n",
       " 'сериала': 2,\n",
       " 'серые': 1,\n",
       " 'скрасит': 1,\n",
       " 'следующих': 1,\n",
       " 'создатели': 1,\n",
       " 'становится': 1,\n",
       " 'стрессах': 1,\n",
       " 'то': 1,\n",
       " 'только': 1,\n",
       " 'успокоить': 1,\n",
       " 'этого': 2,\n",
       " 'я': 2}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\"Великолепный сериал, который поможет успокоить нервы при любых стрессах и просто скрасит серые будни\",\n",
    "         \"Пожалуй, если бы я посмотрел только первые пару сезонов этого сериала, я бы с легкой руки написал ему положительную рецензию\",\n",
    "         \"В общем, если создатели этого сериала не вернут всё на круги своя, то рейтинги следующих сезонов будут становится все ниже и ниже, а зрительская аудитория будет все меньше и меньше и меньше и меньше.\"]\n",
    "\n",
    "Y = [tokenization(t) for t in texts]\n",
    "\n",
    "vectorization = CountVectorizer()\n",
    "res = vectorization.fit_transform(Y)\n",
    "print(res)\n",
    "vectorization.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.12093908 0.\n",
      "  0.         0.         0.12093908 0.         0.         0.\n",
      "  0.         0.         0.         0.09197729 0.12093908 0.\n",
      "  0.         0.12093908 0.         0.         0.         0.\n",
      "  0.12093908 0.         0.         0.         0.         0.\n",
      "  0.12093908 0.         0.12093908 0.12093908 0.         0.\n",
      "  0.         0.         0.         0.         0.12093908 0.\n",
      "  0.12093908 0.12093908 0.         0.         0.         0.12093908\n",
      "  0.         0.         0.12093908 0.         0.        ]\n",
      " [0.08465736 0.         0.         0.         0.         0.\n",
      "  0.16931472 0.         0.         0.         0.         0.\n",
      "  0.08465736 0.0643841  0.         0.         0.         0.\n",
      "  0.08465736 0.         0.         0.         0.08465736 0.\n",
      "  0.         0.         0.         0.08465736 0.08465736 0.08465736\n",
      "  0.         0.08465736 0.         0.         0.         0.08465736\n",
      "  0.08465736 0.08465736 0.         0.0643841  0.         0.0643841\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.08465736 0.         0.0643841  0.16931472]\n",
      " [0.         0.04979845 0.04979845 0.04979845 0.         0.04979845\n",
      "  0.         0.04979845 0.         0.04979845 0.09959689 0.04979845\n",
      "  0.         0.037873   0.04979845 0.15149201 0.         0.04979845\n",
      "  0.         0.         0.19919379 0.04979845 0.         0.04979845\n",
      "  0.         0.09959689 0.04979845 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.04979845 0.\n",
      "  0.         0.         0.04979845 0.037873   0.         0.037873\n",
      "  0.         0.         0.04979845 0.04979845 0.04979845 0.\n",
      "  0.04979845 0.         0.         0.037873   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from mylib.NLP.TFIDF import TFIDFVectorizer\n",
    "\n",
    "\n",
    "vectorization = TFIDFVectorizer()\n",
    "res = vectorization.fit_transform(Y)\n",
    "print(res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Задача классификации спама при помощи векторизации текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/spam.csv\", encoding=\"latin-1\")\n",
    "df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      v1                                                 v2\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro...\n",
       "...   ..                                                ...\n",
       "5567   1  This is the 2nd time we have tried 2 contact u...\n",
       "5568   0              Will Ì_ b going to esplanade fr home?\n",
       "5569   0  Pity, * was in mood for that. So...any other s...\n",
       "5570   0  The guy did some bitching but I acted like i'd...\n",
       "5571   0                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['v1'] = df['v1'].replace({'ham': 0, 'spam': 1})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
       "       'Ok lar... Joking wif u oni...',\n",
       "       \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
       "       ..., 'Pity, * was in mood for that. So...any other suggestions?',\n",
       "       \"The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free\",\n",
       "       'Rofl. Its true to its name'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(df['v2'])\n",
    "y = np.array(df['v1'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [tokenization(x) for x in X]\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = sk.CountVectorizer(min_df=2)\n",
    "matrix = vectorizer.fit_transform(X).todense()\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "pca = PCA(n_components=666)\n",
    "X_pca = pca.fit_transform(np.array(matrix), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.3, stratify=y, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bugae\\ML\\mylib\\classification\\KNN.py:36: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  answer.append(np.around(mode(choise)[0][0]))\n"
     ]
    }
   ],
   "source": [
    "from mylib.classification.KNN import MyKNN\n",
    "\n",
    "\n",
    "nb = MyKNN().fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      1448\n",
      "           1       0.99      0.41      0.58       224\n",
      "\n",
      "    accuracy                           0.92      1672\n",
      "   macro avg       0.95      0.70      0.77      1672\n",
      "weighted avg       0.93      0.92      0.90      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "\n",
    "n_features = 1000\n",
    "n_topics = 10\n",
    "n_top_words = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = sk.CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=n_topics, max_iter=20, \n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0).fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "claim prize yes number urgent customer cash win award contact 10 mobile guarantee holiday service landline receive 150ppm line 1000\n",
      "Topic #1:\n",
      "tell like yeah buy think friend look car reach use stuff got room run drive sorry hello help away amp\n",
      "Topic #2:\n",
      "gt lt send pls right leave like mean want place house problem pay hour day shit change walk office frnd\n",
      "Topic #3:\n",
      "know let guy money hear year care man sure live fuck speak guess hold close search old school worry congrat\n",
      "Topic #4:\n",
      "free text txt ur stop reply mobile www send tone min uk win msg nokia week com 150p new chat\n",
      "Topic #5:\n",
      "day love ur say dear happy good think life morning smile feel nice today amp wish god heart special check\n",
      "Topic #6:\n",
      "thing wait lol new try week long girl person early lose good face baby princess year great sound town luv\n",
      "Topic #7:\n",
      "come ok need hi ask home great babe like tomorrow want hope bad bring ya start big book ill weekend\n",
      "Topic #8:\n",
      "lor da later sorry wat meet watch finish plan wan dun cos ìï minute home happen haha eat thk ur\n",
      "Topic #9:\n",
      "time good want work late night phone message pick thank sleep way soon oh hey talk tonight hope fine miss\n"
     ]
    }
   ],
   "source": [
    "print_top_words(lda, tf_vectorizer.get_feature_names_out(), n_top_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
